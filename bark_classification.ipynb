{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88578005",
   "metadata": {},
   "source": [
    "Importing all required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d0ec42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a40123",
   "metadata": {},
   "source": [
    "Getting the required directory for the multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c85b66a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir='BarkVN-50/BarkVN-50_mendeley'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90050318",
   "metadata": {},
   "source": [
    "Rescalling the images of the training data for the normalization\n",
    "Here we used shear range for seeing the image from view of human's eye\n",
    "Splitting the training set into validation set\n",
    "In the train_datagen we have used target_size=(150,150) and batch_size=64 ,which refers to the number of training examples utilized in one iteration.\n",
    "We used the class_mode=categorical as we need to classify 50 types of categories of bark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6e128bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5039 images belonging to 50 classes.\n",
      "Found 539 images belonging to 50 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen=tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "   rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.4,\n",
    "    validation_split=0.1\n",
    ")\n",
    "test_datagen=tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "     rescale=1./255,\n",
    "    validation_split=0.1\n",
    ")\n",
    "train_datagen=train_datagen.flow_from_directory(\n",
    "     base_dir,\n",
    "    target_size=(150,150),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "test_datagen=test_datagen.flow_from_directory(\n",
    "     base_dir,\n",
    "    target_size=(150,150),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e651d4b5",
   "metadata": {},
   "source": [
    "We have used four layers of neural networks and used the relu activation function.\n",
    "In 1st layer we have used 64 neurons.In 2nd layer we have used 128 neurons.In 3rd layer we have used 256 neurons.In 4th layer we have used 512 neurons.And after applying Conv2D we applied MaxPool2D and used a 2x2 matrix and taking 2 strides.\n",
    "\n",
    "In the output layer I have used the softmax activation function for classifying 50 training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5f3ac2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn=tf.keras.Sequential()\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,activation='relu',input_shape=(150,150,3)))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2))\n",
    "\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=128,kernel_size=3,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=256,kernel_size=3,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=512,kernel_size=3,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "cnn.add(tf.keras.layers.Dense(50,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c04d39",
   "metadata": {},
   "source": [
    "As we have been classifying more than 2 classes so I have used the categorical_crossentropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4be429d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b51282f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "79/79 [==============================] - 145s 2s/step - loss: 3.5929 - accuracy: 0.0988 - val_loss: 5.0229 - val_accuracy: 0.1373\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 149s 2s/step - loss: 2.5081 - accuracy: 0.3330 - val_loss: 2.8171 - val_accuracy: 0.3358\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 154s 2s/step - loss: 1.9640 - accuracy: 0.4620 - val_loss: 2.0241 - val_accuracy: 0.4620\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 152s 2s/step - loss: 1.4978 - accuracy: 0.5765 - val_loss: 2.3208 - val_accuracy: 0.4508\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 152s 2s/step - loss: 1.2701 - accuracy: 0.6378 - val_loss: 2.3150 - val_accuracy: 0.4453\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 151s 2s/step - loss: 1.0355 - accuracy: 0.7025 - val_loss: 2.3121 - val_accuracy: 0.4787\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 152s 2s/step - loss: 0.8808 - accuracy: 0.7450 - val_loss: 2.4943 - val_accuracy: 0.4861\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 152s 2s/step - loss: 0.8138 - accuracy: 0.7613 - val_loss: 1.5824 - val_accuracy: 0.6364\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 152s 2s/step - loss: 0.6652 - accuracy: 0.7984 - val_loss: 2.0492 - val_accuracy: 0.5325\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 151s 2s/step - loss: 0.5629 - accuracy: 0.8254 - val_loss: 2.2977 - val_accuracy: 0.5603\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 151s 2s/step - loss: 0.4541 - accuracy: 0.8649 - val_loss: 1.9814 - val_accuracy: 0.5844\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 151s 2s/step - loss: 0.4908 - accuracy: 0.8490 - val_loss: 1.4739 - val_accuracy: 0.6549\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 152s 2s/step - loss: 0.4228 - accuracy: 0.8708 - val_loss: 1.9705 - val_accuracy: 0.5714\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 156s 2s/step - loss: 0.3755 - accuracy: 0.8839 - val_loss: 1.7064 - val_accuracy: 0.6327\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 154s 2s/step - loss: 0.3031 - accuracy: 0.9065 - val_loss: 1.6796 - val_accuracy: 0.6605\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 162s 2s/step - loss: 0.2802 - accuracy: 0.9107 - val_loss: 1.8413 - val_accuracy: 0.6735\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 154s 2s/step - loss: 0.2437 - accuracy: 0.9234 - val_loss: 2.5157 - val_accuracy: 0.5974\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 153s 2s/step - loss: 0.2498 - accuracy: 0.9254 - val_loss: 1.6860 - val_accuracy: 0.6827\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 156s 2s/step - loss: 0.1876 - accuracy: 0.9391 - val_loss: 1.9846 - val_accuracy: 0.6809\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 157s 2s/step - loss: 0.1880 - accuracy: 0.9383 - val_loss: 1.8968 - val_accuracy: 0.6419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4f2d7b8e20>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(train_datagen,epochs=20,validation_data=test_datagen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c643a0",
   "metadata": {},
   "source": [
    "Initializing the 50 classes of the Bark tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec59b59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Acacia' ,'Adenanthera microsperma', 'Adenium species' , 'Anacardium occidentale' , 'Annona squamosa' ,'Artocarpus altilis' ,'Artocarpus heterophyllus', 'Barringtonia acutangula' ,'Cananga odorata' ,'Carica papaya','Casuarina equisetifolia','Cedrus','Chrysophyllum cainino','Citrus aurantiifolia','Citrus grandis','Cocos nucifera','Dalbergia oliveri','Delonix regia','Dipterocarpus alatus','Erythrina fusca','Eucalyptus','Ficus microcarpa','Ficus racemosa','Gmelina arborea Roxb','Hevea brasiliensis','Hopea','Khaya senegalensis','Khaya senegalensis A.Juss','Lagerstroemia speciosa','Magnolia alba','Mangifera','Melaleuca','Melia azedarach','Musa','Nephelium lappaceum','Persea','Polyalthia longifolia','Prunnus','Prunus salicina','Psidium guajava','Pterocarpus macrocarpus','Senna siamea','Spondias mombin L','Syzygium nervosum','Tamarindus indica','Tectona grandis','Terminalia catappa','Veitchia merrilli','Wrightia','Wrightia religiosa']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38050e7f",
   "metadata": {},
   "source": [
    "Here I have the predicted the top 3 prediction of a particular image taken from a directory.\n",
    "Converted the image into float32 for the less computational power.\n",
    "I also intialize the dictionary's key as the accuracy score and value as classes name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fd6e356e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cedrus\n",
      "Melaleuca\n",
      "Nephelium lappaceum\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "test_image=image.load_img('BarkVN-50/BarkVN-50_mendeley/Cedrus/IMG_6208.JPG',target_size=(150,150))\n",
    "test_image=image.img_to_array(test_image)\n",
    "test_image = test_image.reshape(1,150,150,3)\n",
    "test_image=test_image.astype('float32')\n",
    "test_image  = test_image/255.0\n",
    "result = cnn.predict(test_image)\n",
    "dict_result = {}\n",
    "for i in range(50):\n",
    "        dict_result[result[0][i]] = classes[i]\n",
    "        \n",
    "cnt=0\n",
    "        \n",
    "for i in sorted(dict_result,reverse=True):\n",
    "    if(cnt<3):\n",
    "        print(dict_result[i], end=\"\\n\")\n",
    "        cnt+=1\n",
    "    else :\n",
    "        break\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
